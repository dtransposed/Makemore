{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab1a1995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51dfb2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(420)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efb6dcb",
   "metadata": {},
   "source": [
    "# N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d34f19",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eeacb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifies the train/val/test split \n",
    "#(test will be inferred; it is just the remaining data)\n",
    "\n",
    "train_split = 0.8\n",
    "val_split = 0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91039edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 908 names.\n",
      "\n",
      "Choosing 726 words for training.\n",
      "Choosing 91 words for validation.\n",
      "Choosing 91 words for testing.\n",
      "\n",
      "Our alphabet consists of 27 characters: \n",
      "['.', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "with open('pokemons.json', 'r') as f:\n",
    "    words = json.load(f)['names']\n",
    "\n",
    "# remove weird characters from names\n",
    "words = [re.sub(r'[^a-zA-Z]', '', word) for word in words]\n",
    "\n",
    "# a character that serves as both start and end sentence token\n",
    "special_token = \".\"\n",
    "\n",
    "# prepare an alphabet: Set[str]\n",
    "alphabet = list(set(''.join(words)))\n",
    "alphabet.append(\".\")\n",
    "alphabet.sort()\n",
    "\n",
    "num_training_words = round(train_split * len(words))\n",
    "num_validation_words = round(val_split * len(words))\n",
    "num_test_words = len(words) - (num_training_words + num_validation_words)\n",
    "\n",
    "training_words = words[:num_training_words]\n",
    "validation_words = words[num_training_words:(num_validation_words + num_training_words)]\n",
    "test_words = words[(num_validation_words + num_training_words):]\n",
    "\n",
    "print(f\"The dataset contains {len(words)} names.\\n\")\n",
    "\n",
    "print(f\"Choosing {len(training_words)} words for training.\")\n",
    "print(f\"Choosing {len(validation_words)} words for validation.\")\n",
    "print(f\"Choosing {len(test_words)} words for testing.\\n\")\n",
    "\n",
    "print(f\"Our alphabet consists of {len(alphabet)} characters: \\n{alphabet}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04524540",
   "metadata": {},
   "source": [
    "## Define N-Gram Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc7ae035",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramModel(ABC):\n",
    "    def __init__(self, train, test, alphabet):\n",
    "        self.train = train\n",
    "        self.test = test \n",
    "        self.alphabet = alphabet\n",
    "    \n",
    "    @abstractmethod \n",
    "    def compute_counts(self):\n",
    "        \"\"\"\n",
    "        Auxiliary method for compute_probabilities method that \n",
    "        creates count matrix\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    @abstractmethod\n",
    "    def compute_probabilities(self):\n",
    "        \"\"\"\n",
    "        Compute the NGram model from the training data\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "      \n",
    "    @abstractmethod\n",
    "    def evaluate(self): \n",
    "        \"\"\"\n",
    "        Evaluate of test data\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9fda1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomModel(NGramModel):\n",
    "    \n",
    "    def __init__(self, train, test, alphabet):\n",
    "        super().__init__(train, test, alphabet)\n",
    "        self.counts = self.compute_counts\n",
    "        self.probabilities = self.compute_probabilities()\n",
    "        \n",
    "    def compute_counts(self):\n",
    "        return None\n",
    "      \n",
    "    def compute_probabilities(self):\n",
    "        \"\"\"\n",
    "        Create the Model; an uniform matrix filled with probability values\n",
    "        P(char_next|char_prev) = 1/len(self.alphabet)\n",
    "        \"\"\"\n",
    "        return torch.full([len(self.alphabet), len(self.alphabet)], fill_value = 1/len(self.alphabet))\n",
    "    \n",
    "    def evaluate(self): \n",
    "        \"\"\"\n",
    "        Compute Negative Log Likelihood of the Model\n",
    "        \"\"\"\n",
    "        log_likelihood = 0\n",
    "        count_bigrams = 0\n",
    "        for w in self.test:\n",
    "            chs = [\".\"] + list(w) + [\".\"]\n",
    "            for ch1, ch2 in zip(chs, chs[1:]):\n",
    "                row_index, column_index = self.alphabet.index(ch1), self.alphabet.index(ch2)\n",
    "                log_likelihood += torch.log(self.probabilities[row_index, column_index])\n",
    "                count_bigrams += 1\n",
    "        return -log_likelihood.item()/count_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b78e585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModel(NGramModel):\n",
    "    \n",
    "    def __init__(self, train, test, alphabet, smoothing_counts = 0):\n",
    "        super().__init__(train, test, alphabet)\n",
    "        self.counts = self.compute_counts()\n",
    "        self.probabilities = self.compute_probabilities(smoothing_counts = smoothing_counts)\n",
    "    \n",
    "    def compute_counts(self):\n",
    "        counts = torch.zeros([len(self.alphabet), len(self.alphabet)], dtype=torch.int32)\n",
    "        for w in self.train:\n",
    "            chs = [\".\"] + list(w) + [\".\"]\n",
    "            for ch1, ch2 in zip(chs, chs[1:]):\n",
    "                row_index, column_index = self.alphabet.index(ch1), self.alphabet.index(ch2)\n",
    "                counts[row_index, column_index] += 1\n",
    "        return counts\n",
    "    \n",
    "    def compute_probabilities(self,smoothing_counts):\n",
    "        # adding small number to avoid numerical instabilities\n",
    "        counts = self.counts + 1e-15 + smoothing_counts\n",
    "        probabilities = (counts)/torch.sum(counts, dim=1, keepdim=True)\n",
    "        return probabilities\n",
    "    \n",
    "    def generate(self, generator):\n",
    "        old_char, new_char = \".\", None\n",
    "        name = \"\"\n",
    "        while new_char != special_token:\n",
    "            probs = self.probabilities[self.alphabet.index(old_char)]\n",
    "            sample=torch.multinomial(probs, num_samples=1, replacement=True, generator=generator)\n",
    "            new_char = alphabet[sample.item()]\n",
    "            name += new_char\n",
    "            old_char = new_char\n",
    "        return name[:-1] # removing last character, as it will be \".\"\n",
    "    \n",
    "    def evaluate(self): \n",
    "        \"\"\"\n",
    "        Compute Negative Log Likelihood of the Model\n",
    "        \"\"\"\n",
    "        log_likelihood = 0\n",
    "        count_bigrams = 0\n",
    "        for w in self.test:\n",
    "            chs = [\".\"] + list(w) + [\".\"]\n",
    "            for ch1, ch2 in zip(chs, chs[1:]):\n",
    "                row_index, column_index = self.alphabet.index(ch1), self.alphabet.index(ch2)\n",
    "                log_likelihood += torch.log(self.probabilities[row_index, column_index])\n",
    "                count_bigrams += 1\n",
    "        return -log_likelihood.item()/count_bigrams\n",
    "        \n",
    "    def visualize_counts(self):\n",
    "        plt.figure(figsize=(20,20))\n",
    "        plt.imshow(self.counts)\n",
    "        for i in range(len(self.alphabet)):\n",
    "            for j in range(len(self.alphabet)):\n",
    "                bigram_str = self.alphabet[i] + self.alphabet[j]\n",
    "                plt.text(j, i, bigram_str, ha=\"center\", va = \"bottom\", color=\"gray\")\n",
    "                plt.text(j, i, self.counts[i,j].item(), ha=\"center\", va = \"top\", color=\"gray\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c51f2e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TrigramModel(NGramModel):\n",
    "    def __init__(self, train, test, alphabet, smoothing_counts = 0):\n",
    "        \n",
    "        super().__init__(train, test, alphabet)\n",
    "        \n",
    "        # because of the complexity of the problem, I am storing the mapping\n",
    "        # from bigrams to counts matrix rows (as well as its inverse) in a dictionary\n",
    "        self.bigram_to_index = self.compute_bigram_to_index_mapping()\n",
    "        self.index_to_bigram = {v: k for k, v in self.bigram_to_index.items()}\n",
    "        \n",
    "        self.counts = self.compute_counts()\n",
    "        self.probabilities = self.compute_probabilities(smoothing_counts = smoothing_counts)\n",
    "        \n",
    "    def compute_bigram_to_index_mapping(self):\n",
    "        bigram_to_index = {}\n",
    "        i = 0\n",
    "        for char1 in alphabet:\n",
    "            for char2 in alphabet:\n",
    "                bigram_to_index[char1 + char2] = i\n",
    "                i += 1\n",
    "        return bigram_to_index\n",
    "\n",
    "    \n",
    "    def compute_counts(self):\n",
    "        counts = torch.zeros([len(self.alphabet) * len(self.alphabet), len(self.alphabet)], dtype=torch.int32)\n",
    "        for w in self.train:\n",
    "            chs = [\".\"] + list(w) + [\".\"]\n",
    "            for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "                row_index = self.bigram_to_index[ch1+ch2]\n",
    "                column_index = self.alphabet.index(ch3)\n",
    "                counts[row_index, column_index] += 1\n",
    "        return counts\n",
    "    \n",
    "    def compute_probabilities(self,smoothing_counts):\n",
    "        counts = self.counts + 1e-15 + smoothing_counts\n",
    "        probabilities = (counts)/torch.sum(counts, dim=1, keepdim=True)\n",
    "        # the hack below sets the probability of P(char_next=\".\"|char_prev) = \"..\"\n",
    "        # why would we like to sample an empty word?\n",
    "        probabilities[0][0] = 0\n",
    "\n",
    "        return probabilities\n",
    "            \n",
    "    \n",
    "    def generate(self, generator):\n",
    "        bigram, new_char = \"..\", None\n",
    "        name = \"\"\n",
    "        while new_char != \".\":\n",
    "            probs = self.probabilities[self.bigram_to_index[bigram]]\n",
    "            sample=torch.multinomial(probs, num_samples=1, replacement=True, generator=generator)\n",
    "            new_char = self.alphabet[sample.item()]  \n",
    "            name += new_char\n",
    "            bigram = bigram[1] + new_char\n",
    "        return name[:-1]\n",
    "        \n",
    "    def evaluate(self): \n",
    "        log_likelihood = 0\n",
    "        count_bigrams = 0\n",
    "        for w in self.test:\n",
    "            chs = [\".\"] + list(w) + [\".\"]\n",
    "            for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "                row_index = self.bigram_to_index[ch1+ch2]\n",
    "                column_index = self.alphabet.index(ch3)\n",
    "                log_likelihood += torch.log(self.probabilities[row_index, column_index])\n",
    "                count_bigrams += 1\n",
    "        return -log_likelihood.item()/count_bigrams\n",
    "    \n",
    "    def visualize_counts(self, first_n_rows):\n",
    "        plt.figure(figsize=(20,20))\n",
    "        plt.imshow(self.counts[:first_n_rows,:])\n",
    "        for i in range(first_n_rows):\n",
    "            for j in range(len(alphabet)):\n",
    "                bigram_str = self.index_to_bigram[i] + alphabet[j] \n",
    "                plt.text(j, i, bigram_str, ha=\"center\", va = \"bottom\", color=\"gray\")\n",
    "                plt.text(j, i, self.counts[i,j].item(), ha=\"center\", va = \"top\", color=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6bc8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing_parameter_tuning(n_gram_model_class, parameter_space = 5):\n",
    "    \"\"\"\n",
    "    Hyperparameter tuning on validation set\n",
    "    \"\"\"\n",
    "    nll, best_smoothing = 10000, None\n",
    "    for smoothing in range(parameter_space):\n",
    "        model = n_gram_model_class(train=training_words, test=validation_words, alphabet=alphabet, smoothing_counts=smoothing)\n",
    "        print(f\"Smoothing parameter: {smoothing}, NLL: {model.evaluate()}\")\n",
    "        if model.evaluate() < nll:\n",
    "            nll, best_smoothing = model.evaluate(), smoothing\n",
    "    return best_smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4d3c27",
   "metadata": {},
   "source": [
    "## Evaluate N-Gram Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae454daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothing parameter: 0, NLL: 3.092331807324841\n",
      "Smoothing parameter: 1, NLL: 2.7274323870421973\n",
      "Smoothing parameter: 2, NLL: 2.7469723452428343\n",
      "Smoothing parameter: 3, NLL: 2.7670279533240447\n",
      "Smoothing parameter: 4, NLL: 2.786065012937898\n",
      "-----\n",
      "Smoothing parameter: 0, NLL: 11.105617907961095\n",
      "Smoothing parameter: 1, NLL: 2.836505812939031\n",
      "Smoothing parameter: 2, NLL: 2.9233312249527197\n",
      "Smoothing parameter: 3, NLL: 2.9821752718614913\n",
      "Smoothing parameter: 4, NLL: 3.0241266519947767\n"
     ]
    }
   ],
   "source": [
    "best_smoothing_bigram = smoothing_parameter_tuning(BigramModel)\n",
    "print('-----')\n",
    "best_smoothing_trigram = smoothing_parameter_tuning(TrigramModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "055449aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quality of the Trigram model (NLL): 2.8549500792176574\n",
      "The quality of the Bigram model (NLL): 2.7148289077039394\n",
      "The quality of the Random model (NLL): 3.295827860867711\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Evaluation on the test set\n",
    "\"\"\"\n",
    "random_model = RandomModel(train=training_words, test=test_words, alphabet=alphabet)\n",
    "bigram_model = BigramModel(train=training_words, test=test_words, alphabet=alphabet, smoothing_counts=best_smoothing_bigram)\n",
    "trigram_model = TrigramModel(train=training_words, test=test_words, alphabet=alphabet, smoothing_counts=best_smoothing_bigram)\n",
    "print(f\"The quality of the Trigram model (NLL): {trigram_model.evaluate()}\")\n",
    "print(f\"The quality of the Bigram model (NLL): {bigram_model.evaluate()}\")\n",
    "print(f\"The quality of the Random model (NLL): {random_model.evaluate()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a67f1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigram_model.visualize_counts()\n",
    "#trigram_model.visualize_counts(first_n_rows = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad45db14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names generated by a bigram model:\n",
      "['kos', 'aruir', 'thictamp', 'liolveadr', 'fehianflrilfeodilppicodstron', 'mopet', 'arras', 'kabeolitampilirisinopk', 'swlatened', 'finiostil']\n",
      "----------------------------------\n",
      "Names generated by a bigram model:\n",
      "['fearsh', 'umer', 'yam', 'whinchi', 'esse', 'pa', 'hariza', 'blactilbatuff', 'ill', 'me']\n"
     ]
    }
   ],
   "source": [
    "# for generation, the models without the label smoothing are doing best\n",
    "bigram_model = BigramModel(train=words, test=test_words, alphabet=alphabet)\n",
    "trigram_model = TrigramModel(train=words, test=test_words, alphabet=alphabet)\n",
    "\n",
    "bigram_names = [bigram_model.generate(generator=generator) for _ in range(10)]\n",
    "print(f\"Names generated by a bigram model:\\n{bigram_names}\")\n",
    "print(\"----------------------------------\")\n",
    "trigram_names = [trigram_model.generate(generator=generator) for _ in range(10)]\n",
    "print(f\"Names generated by a bigram model:\\n{trigram_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daf93e5",
   "metadata": {},
   "source": [
    "### Additional excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2442cc",
   "metadata": {},
   "source": [
    "**E01**: Train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?\n",
    "\n",
    "**A:** Using a trigram model increases the number of parameters from $27 * 27$ to $27 * 27* 27$. Given the fact that our dataset is quite limited, I suspect that it is justified that using a model with too much capacity may worsen the results. So all in all, the trigram model does slightly worse then the bigram model, but still significantly better than the baseline (random model).\n",
    "\n",
    "**E02**: Split up the dataset randomly into 80% train set, 10% dev set, 10% test set. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?\n",
    "\n",
    "**A**: This task has been done jointly with E01.\n",
    "\n",
    "**E03**: Use the dev set to tune the strength of smoothing (or regularization) for the trigram model - i.e. try many possibilities and see which one works best based on the dev set loss. What patterns can you see in the train and dev set loss as you tune this strength? Take the best setting of the smoothing and evaluate on the test set once and at the end. How good of a loss do you achieve?\n",
    "\n",
    "**A**: Smoothing equal to one significantly improves the quality of the model over no smoothing - little more regularization of the model improves the generalization. However, further increasing the smoothing leads to increase of entropy and finally, rapid degradation of the model. Best loss with N-Gram models is achieved for Bigram model; I am pretty happy with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9590b6",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bb7eae",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a0c5355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_nn_dataset(words):\n",
    "    inputs, labels = [], []\n",
    "    for w in words:\n",
    "        chs = [\".\"] + list(w) + [\".\"]\n",
    "        for ch1, ch2 in zip(chs, chs[1:]):\n",
    "            row_index, column_index = alphabet.index(ch1), alphabet.index(ch2)\n",
    "            inputs.append(row_index)\n",
    "            labels.append(column_index)\n",
    "    inputs = torch.nn.functional.one_hot(torch.tensor(inputs), num_classes = len(alphabet)).float()\n",
    "    labels = torch.tensor(labels)\n",
    "    return (inputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f18175f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = words_to_nn_dataset(training_words)\n",
    "val_set = words_to_nn_dataset(validation_words)\n",
    "test_set = words_to_nn_dataset(test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6683685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, train_data, val_data, test_data, generator, lr = 20, lambda_ = 0., use_cross_entropy = False): \n",
    "        self.train_inputs, self.train_labels = train_data\n",
    "        self.val_inputs, self.val_labels = val_data\n",
    "        self.test_inputs, self.test_labels = test_data\n",
    "        self.lambda_ = lambda_\n",
    "        self.lr = lr\n",
    "        self.ce = use_cross_entropy\n",
    "        self.W = torch.randn(len(alphabet), len(alphabet), requires_grad = True, generator=generator)\n",
    "        \n",
    "    def nll(self, output, inputs, labels):\n",
    "        loss = -output[torch.arange(inputs.size()[0]), labels].log().mean()\n",
    "        loss += self.lambda_ *(self.W**2).mean()\n",
    "        return loss\n",
    "    \n",
    "    def nll_w_cross_entropy(self, logits, labels):\n",
    "        loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "        loss += self.lambda_ * (self.W**2).mean()\n",
    "        return loss\n",
    "        \n",
    "    def train(self, epochs, verbose = False):\n",
    "        for epoch in range(epochs):\n",
    "            self.W.grad = None\n",
    "            inputs = self.train_inputs\n",
    "            logits = (inputs @ self.W)\n",
    "            if self.ce:\n",
    "                train_loss = self.nll_w_cross_entropy(logits, self.train_labels)\n",
    "            else:\n",
    "                softmax = logits.exp() \n",
    "                softmax = softmax/ softmax.sum(1, keepdims=True)\n",
    "                train_loss = self.nll(softmax, self.train_inputs, self.train_labels)\n",
    "            train_loss.backward()\n",
    "            self.W.data += -self.lr * self.W.grad\n",
    "            \n",
    "            inputs = self.val_inputs\n",
    "            logits = (inputs @ self.W)\n",
    "            val_loss = self.nll_w_cross_entropy(logits, self.val_labels)\n",
    "            if epoch % 100 == 0 and verbose:\n",
    "                print(f\"Epoch: {epoch} | Train loss: {train_loss} | Val loss: {val_loss}\")\n",
    "                \n",
    "    def generate(self, generator):\n",
    "        old_char, new_char = \".\", None\n",
    "        name = \"\"\n",
    "        while new_char != special_token:\n",
    "            logits = mlp.W[alphabet.index(old_char)].exp()\n",
    "            pseudo_probs = logits / logits.sum()\n",
    "            sample=torch.multinomial(pseudo_probs, num_samples=1, replacement=True, generator=generator)\n",
    "            new_char = alphabet[sample.item()]  \n",
    "            name += new_char\n",
    "            old_char = new_char\n",
    "        return name[:-1]\n",
    "    \n",
    "    def evaluate(self):\n",
    "        inputs = self.test_inputs\n",
    "        logits = (inputs @ self.W)\n",
    "        test_loss = self.nll_w_cross_entropy(logits, self.test_labels)\n",
    "        return test_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd9fcaa",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd39f7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 3.701826333999634 | Val loss: 3.5069384574890137\n",
      "Epoch: 100 | Train loss: 2.6354689598083496 | Val loss: 2.745215892791748\n",
      "Epoch: 200 | Train loss: 2.601518154144287 | Val loss: 2.7292656898498535\n",
      "Epoch: 300 | Train loss: 2.590712070465088 | Val loss: 2.726243019104004\n",
      "Epoch: 400 | Train loss: 2.5855460166931152 | Val loss: 2.7253806591033936\n",
      "Epoch: 500 | Train loss: 2.5824830532073975 | Val loss: 2.725008726119995\n",
      "Epoch: 600 | Train loss: 2.5804200172424316 | Val loss: 2.724853515625\n",
      "Epoch: 700 | Train loss: 2.5789215564727783 | Val loss: 2.724848508834839\n",
      "Epoch: 800 | Train loss: 2.5777781009674072 | Val loss: 2.7249608039855957\n",
      "Epoch: 900 | Train loss: 2.5768749713897705 | Val loss: 2.725160837173462\n",
      "Epoch: 1000 | Train loss: 2.576143980026245 | Val loss: 2.7254269123077393\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP(train_data = train_set, val_data = val_set, test_data = test_set, generator=generator)\n",
    "mlp.train(epochs = 1001, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4330b564",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7649658a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quality of the MLP (NLL): 2.7145590782165527\n"
     ]
    }
   ],
   "source": [
    "# notice how similar it is to the Bigram model\n",
    "print(f\"The quality of the MLP (NLL): {mlp.evaluate()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "749b5ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names generated by a bigram model:\n",
      "['kos', 'aruir', 'thictamp', 'liolveadr', 'fehianflrilfeodilppicodstron', 'mopet', 'arras', 'kabeolitampilirisinopk', 'swlatened', 'finiostil']\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP(train_data = words_to_nn_dataset(words), val_data = val_set, test_data = test_set, generator=generator)\n",
    "mlp.train(epochs = 1001)\n",
    "mlp_names = [mlp.generate(generator=generator) for _ in range(10)]\n",
    "print(f\"Names generated by a bigram model:\\n{bigram_names}\")\n",
    "# yay! same names as Bigram model! Andrej did not lie to us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15428c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E04 Answer\n",
    "inputs = []\n",
    "for w in words:\n",
    "    chs = [\".\"] + list(w) + [\".\"]\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        row_index, _ = alphabet.index(ch1), alphabet.index(ch2)\n",
    "        inputs.append(row_index)\n",
    "\n",
    "W = torch.randn(len(alphabet), len(alphabet), requires_grad = True, generator=generator)\n",
    "inputs_ = torch.nn.functional.one_hot(torch.tensor(inputs), num_classes = len(alphabet)).float()\n",
    "assert [True for i in inputs_ @ W == W[inputs]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff10695",
   "metadata": {},
   "source": [
    "### Additional excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5c7b7c",
   "metadata": {},
   "source": [
    "**E04**: We saw that our 1-hot vectors merely select a row of W, so producing these vectors explicitly feels wasteful. Can you delete our use of F.one_hot in favor of simply indexing into rows of W?\n",
    "\n",
    "**A**: Look at the line of code marked as \"E04 Answer\"\n",
    "\n",
    "**E05**: look up and use F.cross_entropy instead. You should achieve the same result. Can you think of why we'd prefer to use F.cross_entropy instead?\n",
    "\n",
    "**A**: Few reasons. It has higher level of abstraction (easy to use it off-the-shelf), can compute NLL between two distributions, maybe computationally more efficient?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralmagic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
