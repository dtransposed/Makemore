
## Training Log

Size of training set: 7809396, size of validation set: 1952349
Let's use 4 GPUs!

Epoch 0, train_loss: 1.037, val_loss: 0.985

Generated text: 
> know of ways or do those predicate of computational scientists. Fhan Logic, when, I want. I'm going to like this. (laughs) Or quantum, and imagine what they've must be like that basis where the field,

Epoch 1, train_loss: 0.922, val_loss: 0.978

Generated text: 
> same kind of machine learning one there's things to be spoken to me that you always think about it's a fundamental interesting machine learning that may you feel comfortable with technology that I und

Epoch 2, train_loss: 0.895, val_loss: 0.982

Generated text: 
> the space of experiments. - Do you hear about NLP why do you think, the number of places efficiently say it's not, I would like to just cause people you know young flapping, but starting with complica

Epoch 3, train_loss: 0.880, val_loss: 0.983

Generated text: 
> Jordan Harbinger show and masks, "If I'm doing the thing." (laughs), very fast, this happened who went through the world. - Right. But it's a difference. - [Lex] From the App, we or a set of functions

## Results


<img src="images/output_gif.gif" width="1020">